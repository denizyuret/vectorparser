<!DOCTYPE html PUBLIC '-//W3C//DTD XHTML 1.0 Strict//EN'
  'http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd'>
<html>
  <head>
    <title>CoNLL-X Shared Task</title>
    <link rel="stylesheet" href="conll.css" type="text/css" />
    <meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1"/>
  </head>

<body>

<div id="mast">

<h1 style="margin-top:0px">CoNLL-X Shared Task: Multi-lingual Dependency Parsing</h1>
<div id="subtitle">Tenth Conference on Computational Natural Language Learning - New York City, June 8-9, 2006</div>

</div>

<!-- ##################################################################### -->

<div id="left">
<div style="margin-right:12px">

<h3 style="margin-top:0px">Contents</h3>

<p>
<a href="#abstract">Abstract</a><br/>
<a href="#register">Register</a><br/>
<a href="#background">Background</a><br/>
<a href="#task">Task definition</a><br/>
<a href="#dataformat">Data format</a><br/>
<a href="#procedure">Procedure</a><br/>
<a href="#dates">Important dates</a><br/>
<a href="#organizers">Organizers</a><br/>
<a href="#unicode">Unicode help</a><br/>
</p>

<h3>Internal links</h3>

<p>
<a href="post_task_data.html">Obtain data</a><br/>
<a href="software.html">Download software</a><br/>
<a href="upload/upload.html">Upload results (closed)</a><br/>
<a href="results.html">Results</a><br/>
<a href="paper_submission.html">Submit paper (closed)</a><br/>
<a href="framework.html">Framework</a><br/>
<a href="programme.html">Workshop programme</a></p>
</p>

<h3>External Links</h3>

<p>
<a href="http://depparse.uvt.nl/depparse-wiki">Depparse Wiki</a><br/>
<a href="http://staff.science.uva.nl/~erikt/signll/conll/">CoNLL Homepage</a><br/>
</p>

<h3>Contact</h3>

<p><a href="mailto:conll06st@uvt.nl">conll06st@uvt.nl</a></p>

<h3>Page statistics</h3>


<!-- Start of StatCounter Code -->
<script type="text/javascript">
<!-- 
var sc_project=1184481; 
var sc_invisible=0; 
var sc_partition=10; 
var sc_security="faefe3c8"; 
//-->
</script>

<script type="text/javascript" src="http://www.statcounter.com/counter/counter_xhtml.js"></script><noscript><div class="statcounter"><a class="statcounter" href="http://www.statcounter.com/"><img class="statcounter" src="http://c11.statcounter.com/counter.php?sc_project=1184481&amp;java=0&amp;security=faefe3c8&amp;invisible=0" alt="counter create hit" /></a></div></noscript>
<!-- End of StatCounter Code --><br/><a href="http://my.statcounter.com/project/standard/stats.php?project_id=1184481&amp;guest=1">site stats</a>


</div>
</div>

<!-- ##################################################################### -->


<div id="middle">

<h2 style="margin-top:0px"><a name="abstract"></a>Abstract</h2>

<p>The shared task of CoNLL-X will be multi-lingual dependency
parsing. Following previous CoNLL shared tasks 
(NP bracketing, chunking, clause identification, language independent
named-entity recognition, and semantic role labeling), this task aims
to define and extend the current state of the art in dependency
parsing - a technology which complements the previous tasks by
producing a different kind of syntactic description of input text.</p>

<p>Ideally, a parser should be trainable for any language, possibly by
adjusting a small number of hyperparameters. The CoNLL-X shared task
will provide the community with a benchmark for evaluating their
parsers across different languages. Because of the variety of
languages and the interest in parser performance across languages, a special
focus of the CoNLL-X shared task will be on a qualitative evaluation
(along with the quantitative scores as before). We will require the
participants to provide an informative error analysis and will
ourselves perform a cross-system comparison. This, we expect, will
result in a clear picture of the problems that lie ahead for
multilingual parsing and the kind of work necessary for adapting
existing parsing architectures across languages.</p>

<p>This page provides a detailed description of the shared task and 
further information regarding scheduling, datasets, paper submission, etc.</p>


<h2><a name="register"></a>Register</h2>

As the main part of the shared task is now passed, you can no longer register for participation. If you want to find out about results, please attend the CoNLL-X workshop at HLT-NAACL 2006 or check the online proceedings afterwards.

<h2><a name="background"></a>Background</h2>

<p>Head-modifier dependency relations have been employed as a useful
representation in several language modelling tasks. These include
unsupervised acquisition of argument structure (<a
href="http://acl.ldc.upenn.edu/A/A97/A97-1052.pdf">Briscoe and
Carroll, 1997</a>; <a
href="http://acl.ldc.upenn.edu/A/A00/A00-2034.pd">McCarthy,
2000</a>), generating word classes (<a
href="http://acl.ldc.upenn.edu/J/J02/J02-2003.pdf">Clark and Weir,
2000</a>) and cooccurence probabilities (<a
href="http://www.cs.biu.ac.il/~dagan/publications/dagan_lee_99.pdf">
Dagan et al., 1999</a>) for disambiguation, and extracting
collocations (<a href="http://acl.ldc.upenn.edu/P/P99/P99-1041.pdf">
Lin, 1999</a>; <a
href="http://www.informatics.susx.ac.uk/users/darrenp/academic/publications/data/Conferences/naacl2001/paper.pdf">
Pearce, 2001</a>). <a
href="http://www.cis.upenn.edu/~mpalmer/papers/kernel.ps.gz">Palmer
et al. (1993)</a> and <a
href="http://xxx.arxiv.org/pdf/cs.CL/0010020">Yeh (2000)</a> used
dependencies as intermediate representations for information
retrieval. In addition, some of the recent parser evaluation schemes
(<a href="http://treebank.linguist.jussieu.fr/pdf/17.pdf">Carroll et
al., 2000</a>; <a
href="http://treebank.linguist.jussieu.fr/pdf/18.pdf">Lin, 2000</a>;
<a href="http://journals.cambridge.org/article_S1351324900002345">
Srinivas, 2000</a>) use dependencies instead of phrases. </p>

<p>Several statistical approaches to full phrase structure parsing
model the probability of dependencies between pairs of words (<a
href="http://acl.ldc.upenn.edu/P/P97/P97-1003.pdf">Collins, 1997</a>;
<a href="http://acl.ldc.upenn.edu/A/A00/A00-2018.pdf">Charniak,
1999</a>).  <a href="http://acl.ldc.upenn.edu/W/W97/W97-0307.pdf">
Brants et al. (1997)</a> report on a markov model for adding
grammatical functions to a phrase structure. Other approaches are
directly aimed at unlabelled (<a
href="http://acl.ldc.upenn.edu/C/C96/C96-1058.pdf">Eisner, 1996</a>;
<a
href="http://www.cis.upenn.edu/~crammer/publications/MS-CIS-05-11.pdf">
McDonald et al. (2005)</a>) or labelled dependency parsing (<a
href="http://www.msi.vxu.se/~nivre/papers/coling04.pdf">Nivre and
Scholz (2004)</a>). </p>

<p>Until a few years ago, parsers have mostly been applied to only one
or two languages: often English and/or the author's native
language. Recently, however, several parsers have been applied to more
languages, e.g. Collins' parsing model has been tested for English,
Czech (<a href="http://acl.ldc.upenn.edu/P/P99/P99-1065.pdf">Collins
et al., 1999</a>), German (<a
href="http://www.coli.uni-sb.de/%7Eadubey/research/negra_parsing.pdf">
Dubey and Keller, 2003</a>), Spanish (<a
href="http://people.csail.mit.edu/brooke/web/papers/emnlp05.pdf">
Cowan and Collins, 2005</a>) and French (<a
href="http://homepages.inf.ed.ac.uk/keller/papers/acl05.pdf">Arun and
Keller, 2005</a>), while Nivre's parser has been tested for English
(<a href="http://www.msi.vxu.se/~nivre/papers/coling04.pdf">Nivre and
Scholz, 2004</a>), Swedish (<a
href="http://www.cnts.ua.ac.be/conll2004/pdf/04956niv.pdf">Nivre et
al., 2004</a>) and Czech (<a
href="http://w3.msi.vxu.se/~nivre/papers/acl05.pdf">Nivre and
Nilsson, 2005</a>). This has resulted in interesting insights into how
the properties of a language or a treebank influence parser
performance, or conversely, how one should best approach parsing for
that language/treebank (see e.g. the above references for
Keller). However, different parsers have been applied to different
subsets of languages. </p>

<p>Ideally, a parser should be trainable for any language, possibly by
adjusting parameters. The CoNLL 2006 shared task will provide the
community members with the possibility of testing their parsers across
different languages. The training and test data for the languages
differ in size, granularity and quality, but we will try to at least
even out differences in the markup format. </p>


<h2>Task definition<a name="task"></a></h2>

<p>The shared task is to assign <b>labeled</b> dependency
structures for a range of languages by means of a fully automatic
dependency parser. Some gold standard dependency structures against
which systems are scored will be <b>non-projective</b>. A system that
produces only projective structures will nevertheless be scored
against the partially non-projective gold standard.
The input consists of 
(minimally) tokenized and part-of-speech tagged sentences. Each
sentence is represented as a sequence of
tokens plus additional features such as lemma, part-of-speech, or
morphological properties. For
each token, the parser must output its head and the corresponding
dependency relation (secondary relations are not taken into
consideration). Although data and settings may vary per language, the
same parser should handle all languages. The parser must therefore be
able to learn from training data, to generalize to unseen test data,
and to handle multiple languages. Participants are expected to submit
parsing results for <b>all</b> languages involved.</p>

<h4>Clarifications (added 22 January 2006)<a name="task_clarify"></a></h4>
<b>What is meant by "the same parser should handle all languages"?</b><br>
For example, if a parsing software package allows the use of several different parsing algorithms or of several different machine learners, are those still "the same parser"? No. So in general, you should choose one parsing algorithm and one learner. However, we realize that it would still be an interesting result of this shared task if it turned out that algorithm/learner X is much better for language/treebank Y while algorithm/learner W is much better for language/treebank Z. So, in line with our focus on an informative error analysis, we allow deviation from your "default" algorithm/learner if you can explain WHY the non-default algorithm/learner is better in some cases. We hope that this will restrict deviations to the really important ones.
<p>
<b>What about pre- and post-processing steps not integrated in the parser itself?</b><br>
That is fine, provided that those steps constitute general approaches (e.g. feature construction, tree manipulation) and not just manual hacks to fix certain errors (e.g. replace relation X in context Y with relation Z).


<h2><a name="dataformat"></a>Data format</h2>

<p>Data adheres to the following rules:</p>


<ul>
<li>Data files contain sentences separated by a blank line.</li> 
<li>A sentence consists of one or tokens, each one starting on a new line.</li> 
<li>A token consists of ten fields described in the table below. 
Fields are separated by a single tab character. 
Space/blank characters are not allowed in within fields</li>
<li>All data files will contains these ten fields, although only the ID, FORM, CPOSTAG,
POSTAG, HEAD and DEPREL columns are guaranteed to contain non-dummy
(i.e. non-underscore) values for all languages.</li>
<li>Data files are UTF-8 encoded (Unicode). If you think this will be
a problem, have a look <a href="#unicode">here</a>.</li>
</ul>

<br/>

<table border="1">
 <thead>
    <tr>
      <th> Field number: </th>
      <th> Field name: </th>
      <th> Description: </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td> 1 </td>
      <td> ID </td>
      <td> Token counter, starting at 1 for each new sentence. </td>
    </tr>
    <tr>
      <td> 2 </td>
      <td> FORM </td>
      <td> Word form or punctuation symbol. </td>
    </tr>
    <tr>
      <td> 3 </td>
      <td> LEMMA </td>
      <td> Lemma or stem (depending on particular data set) of word
form, or an underscore if not available. </td>
    </tr>
    <tr>
      <td> 4 </td>
      <td>CPOSTAG</td>
      <td> Coarse-grained part-of-speech tag, where tagset depends on the language. </td>
    </tr>
    <tr>
      <td> 5 </td>
      <td> POSTAG </td>
      <td> Fine-grained part-of-speech tag, where the tagset depends
on the language, or identical to the coarse-grained part-of-speech tag
if not available. </td>
    </tr>
    <tr>
      <td> 6 </td>
      <td> FEATS </td>
      <td> Unordered set of syntactic and/or morphological features
(depending on the particular language), separated by a vertical bar (|),
or an underscore if not available. </td>
    </tr>
    <tr>
      <td> 7 </td>
      <td> HEAD </td>
      <td> Head of the current token, which is either a value of ID or zero ('0'). 
Note that depending on the original treebank annotation,
there may be multiple tokens with an ID of zero.</td>
    </tr>
    <tr>
      <td> 8 </td>
      <td> DEPREL </td>
      <td> Dependency relation to the HEAD.
The set of dependency relations depends on the particular language. 
Note that depending on the original treebank annotation,
the dependency relation may be meaningfull or simply 'ROOT'.</td>
    </tr>
    <tr>
      <td> 9 </td>
      <td> PHEAD </td>
      <td> Projective head of current token, which is either a
value of ID or zero ('0'), or an underscore if not
available. Note that depending on the original treebank annotation,
there may be multiple tokens an with ID of zero.
The dependency structure resulting from the PHEAD column is
      guaranteed to be projective (but is not available for all
      languages), whereas the structures resulting from the HEAD
      column will be non-projective for some sentences of some
      languages (but is always available). </td>
    </tr>
    <tr>
      <td> 10 </td>
      <td> PDEPREL </td>
      <td> Dependency relation to the PHEAD, or an underscore if not available.  
The set of dependency relations depends on the particular language. 
Note that depending on the original treebank annotation,
the dependency relation may be meaningfull or simply 'ROOT'.</td>
    </tr>
  </tbody>
</table>
<br/>

<p>Here is an <a href="example.html">example</a> from the Dutch data set.</p>



<h2><a name="procedure"></a>Procedure</h2>

<p>We will provide training and test data for about 10 languages from
several language families. The <a href="#dataformat">data format</a>
is the same for all data sets. The details, especially of the
features, vary among languages. The size of the training sets also
varies with language, but the test sets will be of approximately the
same size for all the languages: about 5000 "scoring"
tokens. Punctuation is not a scoring token. </p>

<p>Whether we can make data freely available for download depends
on the license type of the source treebank. <a href="download_data.html">Some data sets</a> can be made
freely available under an open source
license, other data sets require participants to sign and send a
license agreement first. Therefore, if you are interested in
participating, please 
<a href="#register">register</a> as early as possible. We will then
inform you about the details of the licensing procedure. No fee will
be required for any data.</p>

<p>In order to allow participants to start developing systems early
on, some preliminary data sets will be made available by December
12. We cannot yet provide final information as to which languages will
be represented in the shared task as we are still in the process of
searching for appropriate treebanks, assessing suitability,
negotiating licenses (if necessary) and converting to the common
format. Final data sets will be made available by 9 January 2006 at
the latest.</p>

<p>Unparsed test data for all languages will be released on March
6. This data will contain the first six columns, although only the ID,
FORM, CPOSTAG and POSTAG columns are guaranteed to contain
non-underscore values. Participants are given three days to run their
parsers on the test data. Parsed test data must be returned on March
9. (Details to be supplied later...) Parsed data must include all original columns from the unparsed
data plus the HEAD and DEPREL column. Only the score on the HEAD and
DEPREL counts for the evaluation; the PHEAD and PDEPREL columns will
be ignored. Optionally, participants can submit additional results
obtained by using external data or knowledge sources.</p>

<p>The evaluation metric is <b>labeled attachment score</b>: 
 the proportion of "scoring" tokens that are assigned both the correct head and 
 the correct dependency relation label. </p>

<p>Punctuation tokens are non-scoring. In very exceptional cases, and depending on the original
treebank annotation, some additional types of tokens might also be
non-scoring. This will clearly be marked in the README accompanying
such data. </p>

<p>The overall score of a system is its labeled attachment score on all
test sets taken together.</p>

<p>The <b>unlabeled attachment score</b> will be provided as well, but
the overall ranking of a system will be based on the labeled
attachment score. Unlabeled attachement score is the proportion of
"scoring" tokens that are assigned the correct head (regardless of the
dependency relation label). </p>

<p>We will return the score on the test data, as well as the gold
standard answers, on March 10. Partipants are then invited to submit a
paper describing their approach and results. Because of the variety of
languages and the interest in parser performance across languages, a special
focus of the CoNLL 2006 shared task will be on a qualitative evaluation:
we will prefer papers with an informative error analysis and ask the participants
to discuss performance on two languages.
<!--Moreover, we will ask participants to discuss performance on two specific
languages, in such a way that different participants discuss different languages. -->
In support, we include the documentation of the original
treebanks that the data were derived from, as well as some
typological information in order to give
participants a flavour of languages with which they may not be
familiar. We will also supply an evaluation tool to discover
structural parser errors.</p>

<p>We will perform a cross-system comparison which we expect to result
in a clear picture of the problems that lie ahead for multilingual
parsing and the kind of work necessary for adapting existing parsing
architectures across languages. </p>

<p>Our <a href="framework.html">Framework</a> page aims to provide an
overview of existing work on dependency parsing. We hope that it will
be useful as a starting point for participants who have not yet
decided their approach and as inspiration for improvements for those
who have. </p>

<h2>Important dates<a name="dates"></a></h2>

<br/>

<table border="1">
  <tbody>
    <tr>
      <td>December 12</td>
      <td>Preliminary release of training data and software</td>
    </tr>
    <tr>
      <td>January 9</td>
      <td>Final release of training data and software</td>
    </tr>
    <tr>
      <td>March 6</td>
      <td>Release of the test data</td>
    </tr>
    <tr>
      <td>March 10 at 8:00 am GMT<br/>(Greenwich Mean Time)</td>
      <td>Submission of results on the test data</td>
    </tr>
    <tr>
      <td>March 10 </td>
      <td>Scoring and release of gold standard answers for the test data</td>
    </tr>
    <tr>
      <td>March 20 at 8:00 am GMT<br/>(Greenwich Mean Time)</td>
      <td>Deadline for paper submissions</td>
    </tr>
    <tr>
      <td>April 10</td>
      <td>Notification of acceptance</td>
    </tr>
    <tr>
      <td>April 24 at 8:00 am GMT<br/>(Greenwich Mean Time)</td>
      <td>Deadline for camera ready copy</td>
    </tr>
  </tbody>
</table>


<h2><a name="register"></a>Register</h2>

<p>If you are interested in participating, please send an email with your
name and affiliation to <a
href="mailto:conll06st@uvt.nl">conll06st@uvt.nl</a> We would also like
to know whether your institution is a member of <a
href="http://www.ldc.upenn.edu/">LDC</a> (and for which years) as this
information might help in negotiating license-restricted data. </p>


<h2><a name="organizers"></a>Organizers</h2>

<p>Sabine Buchholz<br />
Toshiba Research Europe Ltd (UK)<br />
 sabine dot buchholz at crl dot toshiba dot co dot uk </p>

<p>Erwin Marsi<br />
Tilburg University (The Netherlands)<br />
e dot c dot marsi at uvt dot nl</p>

<p>Yuval Krymolowski<br /> 
University of Haifa (Israel)<br />
yuval at cl.haifa.ac.il</p>

<p>Amit Dubey<br />
University of Edinburgh (UK)<br />
adubey at inf dot ed dot ac dot uk </p>


<h2><a name="unicode"></a>Unicode help</h2>

<p>Much information about Unicode can be found on the internet, see
e.g. the <a href="http://en.wikipedia.org/wiki/Unicode">Wikipedia
article on Unicode</a> or <a href="http://www.cl.cam.ac.uk/~mgk25/">Markus
Kuhn</a>'s <a href="http://www.cl.cam.ac.uk/~mgk25/unicode.html">UTF-8
and Unicode FAQ for Unix/Linux</a>. </p>

<p>If you have an existing dependency parser that cannot support
Unicode, you can convert the data to ASCII and back without loosing
any information by using numerical character references
(e.g. <samp>&#350;</samp> becomes <samp>&amp;#350;</samp>). See the <a
href="http://www.cl.cam.ac.uk/~mgk25/unicode.html#perl">Useful Perl
one-liners for working with UTF-8</a>. </p>

<p>However, many programming and scripting languages nowadays offer
Unicode support. Make sure though that you are using a new version of
the software as earlier versions often contain bugs in their treatment
of Unicode that can result in totally unexpected results. If in any
doubt about the cause of unexpected behaviour, replace Unicode with
ASCII characters and see whether it works then.</p>

<p>Also, many editors can now render UTF-8 encoded text. E.g. in emacs, a
little "u" in the left corner of the status bar indicates that the
currently displayed file is UTF-8 encoded.</p>

</div>


<!-- ##################################################################### -->

<div id="right" >
<div style="margin-left:12pt">
<h3  style="margin-top:0px">News</h3>

<div class="newsitem">June 14 2006:</div>
<p><a href="programme.html">Presentation slides linked in</a></p>

<div class="newsitem">June 4 2006:</div>
<p><a href="software.html#conversion">Released our treebank conversion software</a>;<br>A dynamic site for the future: <a href="http://depparse.uvt.nl/depparse-wiki">the Depparse Wiki</a><br/>
</p>

<div class="newsitem">May 10 2006:</div>
<p><a href="programme.html">Workshop programme</a></p>

<div class="newsitem">May 9 2006:</div>
<p>An interactive <a href="http://ilk.uvt.nl/cgi-bin/yuval/scripts/menu.pl">evaluation menu</a>
for viewing complete evaluations or result tables.</p>
	
<div class="newsitem">May 7 2006:</div>
<p>Complete <a href="results.html">results</a></p>

<div class="newsitem">April 5 2006:</div>
<p>More space for reporting your findings, read <a href="paper_submission.html#tb_ref">Treebank references</a></p>

<div class="newsitem">March 31 2006:</div>
<p><a href="software.html">Linked</a> to <a href="http://www.ifi.unizh.ch/cl/kalju/download/depsvg/">Kaarel Kaljurand's tree visualizer</a></p>

<div class="newsitem">March 13 2006:</div>
<p><a href="results.html">Results: averages and top three</a></p>

<div class="newsitem">March 12 2006:</div>
<p>Support for significance testing in <a href="software.html#eval">eval.pl</a></p>

<div class="newsitem">March 11 2006:</div>
<p><ul>
<li>Release of the <a href="free_data.html#testdata">gold standard test data</a> (other parts password protected)
<li>Detailed instructions for <a href="paper_submission.html">paper submissions</a>
</ul></p>

<div class="newsitem">March 7 2006:</div>
<p><ul>
<li><a href="http://nextens.uvt.nl/~conll/upload/upload.html">page</a>
for uploading parsed test data is ready</li>
<li>release of the data format validation <a href="software.html#validate">script</a></li>
<li>Final deadline for submitting results is March 10 at 8:00 GMT</li>
</ul></p>

<div class="newsitem">March 6 2006:</div>
<p>Release of the <a href="free_data.html#testdata_blind">unparsed test data</a> (other parts password protected)</p>

<div class="newsitem">March 2 2006:</div>
<p>A change in the <a href="#procedure">procedure</a>: participants are free to decide on the two languages for which they will present a detailed error analysis.</p>

<div class="newsitem">February 8 2006:</div>
<p><a href="paper_submission.html#bibtex">BibTeX entries</a> and <a href="paper_submission.html#table">data overview table</a>; more output in <a href="software.html#eval">evaluation script</a>
</p>

<div class="newsitem">February 1 2006:</div>
<p><a href="http://nextens.uvt.nl/conll-wiki/BugReports">Corrected</a> version of Chinese data (password restricted)
</p>

<div class="newsitem">January 22 2006:</div>
<p><ul>
<li><a href="#task_clarify">Clarified task definition</a>
<li>New release and clarifications for <a href="software.html#eval">evaluation script</a>
<li><a href="http://nextens.uvt.nl/conll-wiki/BugReports">Corrected</a> version of Bulgarian data (password restricted)
</ul></p>

<div class="newsitem">January 13 2006:</div>
<p><a href="http://nextens.uvt.nl/conll-wiki/BugReports">Corrected</a> version of <a href="free_data.html#dutch">Dutch data</a></p>

<div class="newsitem">January 9 2006:</div>
<p><a href="release_notes.html">Final release of training data and software</a>.
</p>

<div class="newsitem">January 6 2006:</div>
<p>Some minor changes in the <a href="#dataformat">data format</a>:</p>
<ul>
<li>fields are separated by a single tab character instead of multiple spaces</li>
<li>dependency relation of a token with a value of '0' for HEAD is not necessarily 'ROOT'</li>
<li>space/blank characters are not allowed within fields</li>
</ul>

<div class="newsitem">December 15 2005:</div>
<p><a href="#dataformat">Non-uniqueness of ROOT clarified</a>.
</p>

<div class="newsitem">December 14 2005:</div>
<p><a href="data/licensed_data/licensed_data.html">First license online</a>.
</p>

<div class="newsitem">December 12 2005:</div>
<p>Preliminary data sets released.
</p>

<div class="newsitem">December 6 2005:</div>
<p>First call for papers for CoNLL-X
</p>
</div>
</div>

<!-- ##################################################################### -->

<div id="footer" >
<div style="float:left">
<a href="http://validator.w3.org/check?uri=http://nextens.uvt.nl/~conll/index.html">
   <img style="border:none" src="http://www.w3.org/Icons/valid-xhtml10"
 alt="Valid XHTML 1.0 Strict" height="31" width="88" /></a>
<a href="http://jigsaw.w3.org/css-validator/validator?uri=http://nextens.uvt.nl/~conll/index.html">
  <img style="border:0;width:88px;height:31px" src="http://jigsaw.w3.org/css-validator/images/vcss" 
  alt="Valid CSS!" /></a>
</div>
<a style="float:right" href="mailto:conll06st@uvt.nl">conll06st@uvt.nl</a><br/>
<div style="float:right"><tt>Last updated by $Author: sabine $ at $Date: 2006/06/14 11:22:16 $ ($Revision: 1.52 $)</tt></div>
</div>

</body>
</html>
